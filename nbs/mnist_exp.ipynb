{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21d34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.nce.cd_cnce import CdCnceCrit\n",
    "from src.nce.cd_mh_cnce import CdMHCnceCrit\n",
    "from src.nce.per_cnce import PersistentCondNceCrit\n",
    "from src.nce.per_cnce_batch import PersistentCondNceCritBatch\n",
    "from src.nce.per_cnce_batch_eps import PersistentCondNceCritBatchEps\n",
    "from src.cd.rbm_crit import RbmCrit\n",
    "from src.cd.cd_gibbs import CdGibbsCrit\n",
    "from src.cd.pers_cd_gibbs import PersistentCdGibbsCrit\n",
    "from src.cd.pers_cd_gibbs_batch import PersistentCdGibbsCritBatch\n",
    "\n",
    "from src.noise_distr.rbm_noise_distr import RbmNoiseDistr, ConditionalRbmNoiseDistr\n",
    "from src.noise_distr.bernoulli import MultivariateBernoulli\n",
    "from src.noise_distr.conditional_bernoulli import ConditionalMultivariateBernoulli, SpatialConditionalMultivariateBernoulli\n",
    "from src.noise_distr.uniform_sphere import UniformSphere\n",
    "from src.noise_distr.conditional_sphere import ConditionalSphere\n",
    "\n",
    "from src.models.rbm.rbm import Rbm\n",
    "from src.models.ebm.two_layer_ebm import Ebm\n",
    "from src.data.mnist import MnistDataset\n",
    "\n",
    "from src.training.model_training import train_model\n",
    "from src.training.training_utils import no_stopping\n",
    "\n",
    "from src.experiments.mnist_exp_utils import initialise_ebm_params, initialise_rbm_params\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4307bfe",
   "metadata": {},
   "source": [
    "## EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4eb4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data specs\n",
    "img_dim = 28\n",
    "num_dims = img_dim**2\n",
    "\n",
    "# Model specs\n",
    "num_hidden = 1000\n",
    "\n",
    "# Training specs\n",
    "num_neg_samples = 5\n",
    "lr = 0.1\n",
    "batch_size = 64\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40698ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy of model\n",
    "def rbm_acc(rbm, data_loader, k=100):\n",
    "    acc = 0\n",
    "    for i, (y, idx) in enumerate(data_loader, 0):\n",
    "        _, y_pred = rbm.sample(y, k=k)\n",
    "        acc += (y_pred == y).type(torch.float).mean(dim=-1).sum()\n",
    "        \n",
    "    return acc / len(data_loader.dataset)\n",
    "\n",
    "def placeholder_metric(model):\n",
    "    return model.weights.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations to consider in experiments \n",
    "\n",
    "config_conditional_multi = {\n",
    "    \"criterion\": CdCnceCrit,\n",
    "    \"label\": \"cd_cnce\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": 1,\n",
    "}\n",
    "\n",
    "config_per_cnce = {\n",
    "    \"criterion\": PersistentCondNceCrit,\n",
    "    \"label\": \"per_cnce\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": None,\n",
    "}\n",
    "\n",
    "config_per_cnce_batch = {\n",
    "    \"criterion\": PersistentCondNceCritBatch,\n",
    "    \"label\": \"per_cnce_batch\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": None,\n",
    "}\n",
    "\n",
    "\n",
    "config_per_cnce_batch_eps = {\n",
    "    \"criterion\": PersistentCondNceCritBatchEps,\n",
    "    \"label\": \"per_cnce_batch\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": None,\n",
    "}\n",
    "\n",
    "\n",
    "config_cd_mh = {\n",
    "    \"criterion\": CdMHCnceCrit,\n",
    "    \"label\": \"cd_mh\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": 1,\n",
    "}\n",
    "\n",
    "\n",
    "config_rbm_crit = {\n",
    "    \"criterion\": CdGibbsCrit,\n",
    "    \"label\": \"cd_gibbs\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": 1,\n",
    "}\n",
    "\n",
    "\n",
    "config_cd_gibbs = {\n",
    "    \"criterion\": RbmCrit,\n",
    "    \"label\": \"cd_gibbs\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": 1,\n",
    "}\n",
    "\n",
    "\n",
    "config_pers_gibbs = {\n",
    "    \"criterion\": PersistentCdGibbsCrit,\n",
    "    \"label\": \"pers_gibbs\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": None,\n",
    "}\n",
    "\n",
    "\n",
    "config_pers_gibbs_batch = {\n",
    "    \"criterion\": PersistentCdGibbsCritBatch,\n",
    "    \"label\": \"pers_gibbs_batch\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": None,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Vi vill jämföra de två första (de övriga är bara med som tillfälliga referenser)\n",
    "configs = [config_per_cnce_batch_eps]#config_per_cnce_batch, config_per_cnce_batch_eps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c8c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data \n",
    "training_data = MnistDataset(train=True, root_dir=\"../src/data/datasets/\")\n",
    "rel_inds = (training_data.targets == 0) + (training_data.targets == 1) + (training_data.targets == 2) + (training_data.targets == 3) + (training_data.targets == 4)\n",
    "training_data.y = training_data.y[rel_inds, :]\n",
    "training_data.num_samples = training_data.y.shape[0]\n",
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "                             \n",
    "test_data = MnistDataset(train=False, root_dir=\"../src/data/datasets/\")\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090b9998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise model       \n",
    "weights, vis_bias, hidden_bias = initialise_rbm_params(num_visible=num_dims, num_hidden=num_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935b71c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cond_bern_params(y, eps=1e-1):\n",
    "    num_dims = y.shape[-1]\n",
    "    p_0, p_1 = torch.zeros((num_dims,)), torch.zeros((num_dims,))\n",
    "    for i in range(num_dims):\n",
    "                \n",
    "        if y[y[:, i] < 0.5, i].size()[0] == 0:\n",
    "            p_0[i] = 0.5\n",
    "        else:\n",
    "            p_0[i] = y[y[:, i] < 0.5, i].mean()\n",
    "        \n",
    "        if y[y[:, i] >= 0.5, i].size()[0] == 0:\n",
    "            p_1[i] = 0.5\n",
    "        else:\n",
    "            p_1[i] = y[y[:, i] >= 0.5, i].mean()\n",
    "\n",
    "    p_0[p_0 < eps] = eps\n",
    "    p_1[p_1 > 1 - eps] = 1 - eps\n",
    "    return p_0, p_1\n",
    "        \n",
    "p_0, p_1 = get_cond_bern_params(training_data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c568dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test noise distr. params\n",
    "\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "\n",
    "num_samples = 16\n",
    "y_true = training_data.y[:num_samples, :].clone()\n",
    "y_true[y_true >= 0.5] = 1.0\n",
    "y_true[y_true < 0.5] = 0.0\n",
    "\n",
    "p_n_test = ConditionalMultivariateBernoulli(p_0, p_1) # \n",
    "\n",
    "y_sample = p_n_test.sample(torch.Size((num_samples, 1)), y_true.reshape(-1, 1, y_true.shape[-1]))\n",
    "\n",
    "\n",
    "ax[0].imshow(np.transpose(torchvision.utils.make_grid(y_true.reshape(-1, 1, 28, 28), nrow=4).numpy(), (1, 2, 0)))\n",
    "ax[1].imshow(np.transpose(torchvision.utils.make_grid(y_sample.reshape(-1, 1, 28, 28), nrow=4).numpy(), (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a08bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiments\n",
    "\n",
    "for config in configs:\n",
    "    \n",
    "    # Make sure that these are \"reinitialised\"\n",
    "    p_m, p_n, criterion = None, None, None\n",
    "\n",
    "    p_m = Rbm(weights=weights.clone(), vis_bias=vis_bias.clone(), hidden_bias=hidden_bias.clone())\n",
    "\n",
    "    \n",
    "    if config[\"conditional_noise_distr\"]:\n",
    "        p_n = RbmNoiseDistr(p_m) #ConditionalMultivariateBernoulli(p_0, p_1)\n",
    "    else:\n",
    "        p_n = None\n",
    "   \n",
    "    if config[\"mcmc_steps\"] is not None:\n",
    "        criterion = config[\"criterion\"](p_m, p_n, num_neg_samples, config[\"mcmc_steps\"])\n",
    "    else:\n",
    "        criterion = config[\"criterion\"](p_m, p_n, num_neg_samples)\n",
    "\n",
    "    save_dir = None\n",
    "    _ = train_model(criterion, placeholder_metric, train_loader, save_dir, num_epochs=num_epochs,\n",
    "                    decaying_lr=True, weight_decay=1e-2, stopping_condition=no_stopping)\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(p_m.state_dict(), \"res/params_rbm_\" + config[\"label\"])\n",
    "    \n",
    "    # Check test accuracy of model\n",
    "    #acc = rbm_acc(p_m, test_loader)\n",
    "    #print(\"Model accuracy: {}\".format(acc))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b6037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "\n",
    "num_samples = 8\n",
    "fig, ax = plt.subplots(len(configs), 2)\n",
    "\n",
    "\n",
    "if ax.ndim == 1:\n",
    "    ax = ax.reshape(1, -1)\n",
    "\n",
    "p_m = Rbm(weights=weights.clone(), vis_bias=vis_bias.clone(), hidden_bias=hidden_bias.clone())\n",
    "\n",
    "for i, config in enumerate(configs):\n",
    "    p_m.load_state_dict(torch.load(\"res/params_rbm_\" + config[\"label\"]))\n",
    "    \n",
    "    y_true = training_data.y[:num_samples, :] #  torch.distributions.Bernoulli(0.5).sample((num_samples, num_dims)) #\n",
    "    y_true_pred_prob, y_true_pred = p_m.sample(y_true.clone(), k=10000)\n",
    "    \n",
    "    y_noise = torch.distributions.Bernoulli(0.5).sample((num_samples, num_hidden))  \n",
    "    y_pred_prob, y_pred = p_m.sample_from_hidden(y_noise, k=10000) \n",
    "    \n",
    "    ax[i, 0].imshow(np.transpose(torchvision.utils.make_grid(y_true_pred_prob.reshape(-1, 1, 28, 28), nrow=4).numpy(), (1, 2, 0)))\n",
    "    ax[i, 0].set_title(config[\"label\"] + \" predicted proabilities\")\n",
    "    \n",
    "    ax[i, 1].imshow(np.transpose(torchvision.utils.make_grid(y_pred_prob.reshape(-1, 1, 28, 28), nrow=4).numpy(), (1, 2, 0)))\n",
    "    ax[i, 1].set_title(config[\"label\"] + \" samples\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c085e4f3",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d4fc31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
