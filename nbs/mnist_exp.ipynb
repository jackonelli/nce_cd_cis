{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b21d34e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.nce.cd_cnce import CdCnceCrit\n",
    "from src.nce.cd_mh import CdMHCrit\n",
    "from src.nce.per_cnce import PersistentCondNceCrit\n",
    "\n",
    "from src.noise_distr.rbm_noise_distr import RbmNoiseDistr\n",
    "\n",
    "from src.models.rbm.rbm import Rbm\n",
    "from src.data.mnist import MnistDataset\n",
    "\n",
    "from src.training.model_training import train_model\n",
    "from src.training.training_utils import no_stopping\n",
    "\n",
    "from src.experiments.noise_distr_utils import get_nce_noise_distr_par, get_cnce_noise_distr_par\n",
    "from src.experiments.mnist_exp_utils import initialise_params\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4307bfe",
   "metadata": {},
   "source": [
    "## EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fa4eb4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data specs\n",
    "num_dims = 28**2\n",
    "\n",
    "# Training specs\n",
    "num_neg_samples = 2\n",
    "lr = 0.01\n",
    "batch_size = 100\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "40698ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy of model\n",
    "def rbm_acc(rbm, data_loader, k=100):\n",
    "    acc = 0\n",
    "    for i, (y, idx) in enumerate(data_loader, 0):\n",
    "        y_pred = rbm.sample(y, k=k)\n",
    "        acc += (y_pred == y).type(torch.float).mean(dim=-1).sum()\n",
    "        \n",
    "    return acc / len(data_loader.dataset)\n",
    "\n",
    "def placeholder_metric(model):\n",
    "    return model.weights.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "655c310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations to consider in experiments \n",
    "\n",
    "config_conditional_multi = {\n",
    "    \"criterion\": CdCnceCrit,\n",
    "    \"label\": \"cd_cnce\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": 1,\n",
    "}\n",
    "\n",
    "config_per_cnce = {\n",
    "    \"criterion\": PersistentCondNceCrit,\n",
    "    \"label\": \"cd_cnce\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": None,\n",
    "}\n",
    "\n",
    "config_cd_mh = {\n",
    "    \"criterion\": CdMHCrit,\n",
    "    \"label\": \"cd_mh\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": 1,\n",
    "}\n",
    "\n",
    "\n",
    "configs = [config_conditional_multi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e82c8c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data \n",
    "training_data = MnistDataset(train=True, root_dir=\"../src/data/datasets/\")\n",
    "training_data.y = training_data.y[:1000, :]\n",
    "training_data.num_samples = 1000\n",
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "                             \n",
    "test_data = MnistDataset(train=False, root_dir=\"../src/data/datasets/\")\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "090b9998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise model       \n",
    "weights, vis_bias, hidden_bias = initialise_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b8a08bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.6651,  0.3381,  0.4760,  ...,  0.4964, -0.2129, -1.8085],\n",
      "        [ 0.7247, -1.2400,  0.6758,  ...,  1.5936,  0.3555, -0.0097],\n",
      "        [ 0.5953,  1.6994, -0.8222,  ..., -0.1145, -1.3786,  0.1230],\n",
      "        ...,\n",
      "        [-1.4755,  0.2359,  0.4390,  ...,  1.7254, -0.6167,  1.1069],\n",
      "        [ 0.4023,  0.2165, -0.7193,  ..., -0.1915, -1.4089,  0.6499],\n",
      "        [ 0.1802,  0.1032,  0.9323,  ..., -1.1254,  0.3332, -1.6849]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.6651,  0.3381,  0.4760,  ...,  0.4964, -0.2129, -1.8085],\n",
      "        [ 0.7247, -1.2400,  0.6758,  ...,  1.5936,  0.3555, -0.0097],\n",
      "        [ 0.5953,  1.6994, -0.8222,  ..., -0.1145, -1.3786,  0.1230],\n",
      "        ...,\n",
      "        [-1.4755,  0.2359,  0.4390,  ...,  1.7254, -0.6167,  1.1069],\n",
      "        [ 0.4023,  0.2165, -0.7193,  ..., -0.1915, -1.4089,  0.6499],\n",
      "        [ 0.1802,  0.1032,  0.9323,  ..., -1.1254,  0.3332, -1.6849]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], requires_grad=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter probs (Tensor of shape (200, 1, 500)) of distribution Bernoulli(probs: torch.Size([200, 1, 500])) to satisfy the constraint Interval(lower_bound=0.0, upper_bound=1.0), but found invalid values:\ntensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n\n        [[nan, nan, nan,  ..., nan, nan, nan]],\n\n        [[nan, nan, nan,  ..., nan, nan, nan]],\n\n        ...,\n\n        [[nan, nan, nan,  ..., nan, nan, nan]],\n\n        [[nan, nan, nan,  ..., nan, nan, nan]],\n\n        [[nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<SigmoidBackward0>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [144]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     criterion \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m\"\u001b[39m](p_m, p_n, num_neg_samples)\n\u001b[0;32m     17\u001b[0m save_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplaceholder_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdecaying_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstopping_condition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_stopping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Check test accuracy of model\u001b[39;00m\n\u001b[0;32m     22\u001b[0m acc \u001b[38;5;241m=\u001b[39m rbm_acc(p_m, test_loader)\n",
      "File \u001b[1;32m~\\PycharmProjects\\deep_ext_obj\\nbs\\..\\src\\training\\model_training.py:35\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(criterion, evaluation_metric, train_loader, save_dir, num_epochs, weight_decay, lr, decaying_lr, stopping_condition)\u001b[0m\n\u001b[0;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Calculate and assign gradients\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_crit_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(criterion\u001b[38;5;241m.\u001b[39m_noise_distr\u001b[38;5;241m.\u001b[39m_inner_distr\u001b[38;5;241m.\u001b[39mweights)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(criterion\u001b[38;5;241m.\u001b[39m_unnorm_distr\u001b[38;5;241m.\u001b[39mweights)\n",
      "File \u001b[1;32m~\\PycharmProjects\\deep_ext_obj\\nbs\\..\\src\\nce\\cd_cnce.py:34\u001b[0m, in \u001b[0;36mCdCnceCrit.calculate_crit_grad\u001b[1;34m(self, y, _idx)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_crit_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m, y: Tensor, _idx: Optional[Tensor]):\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# We will have N*J pairs\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrepeat_interleave(y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_neg, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m     y_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_noise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_inner_crit_grad(y, y_samples)\n",
      "File \u001b[1;32m~\\PycharmProjects\\deep_ext_obj\\nbs\\..\\src\\part_fn_base.py:57\u001b[0m, in \u001b[0;36mPartFnEstimator.sample_noise\u001b[1;34m(self, num_samples, y)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample_noise\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_samples: \u001b[38;5;28mint\u001b[39m, y: Tensor):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Note: num_samples = samples / obs.\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_noise_distr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\deep_ext_obj\\nbs\\..\\src\\noise_distr\\rbm_noise_distr.py:15\u001b[0m, in \u001b[0;36mRbmNoiseDistr.sample\u001b[1;34m(self, size, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, size: torch\u001b[38;5;241m.\u001b[39mSize, x: Tensor):\n\u001b[0;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrepeat_interleave(x, size[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inner_distr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone()\n",
      "File \u001b[1;32m~\\PycharmProjects\\deep_ext_obj\\nbs\\..\\src\\models\\rbm\\rbm.py:52\u001b[0m, in \u001b[0;36mRbm.sample\u001b[1;34m(self, y, k)\u001b[0m\n\u001b[0;32m     50\u001b[0m v \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k):\n\u001b[1;32m---> 52\u001b[0m     _, h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_hidden\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     _, v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_visible(h)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m v\n",
      "File \u001b[1;32m~\\PycharmProjects\\deep_ext_obj\\nbs\\..\\src\\models\\rbm\\rbm.py:37\u001b[0m, in \u001b[0;36mRbm.sample_hidden\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample_hidden\u001b[39m(\u001b[38;5;28mself\u001b[39m, y: Tensor):\n\u001b[0;32m     36\u001b[0m     p_h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_model(y))\n\u001b[1;32m---> 37\u001b[0m     sample_h \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbernoulli\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBernoulli\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp_h\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p_h, sample_h\n",
      "File \u001b[1;32mC:\\MyPrograms\\continuum\\Anaconda3\\envs\\torchenv3\\lib\\site-packages\\torch\\distributions\\bernoulli.py:49\u001b[0m, in \u001b[0;36mBernoulli.__init__\u001b[1;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m     batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mBernoulli\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\MyPrograms\\continuum\\Anaconda3\\envs\\torchenv3\\lib\\site-packages\\torch\\distributions\\distribution.py:55\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[1;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[0;32m     53\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m---> 55\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     56\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     58\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     59\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     60\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     61\u001b[0m             )\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28msuper\u001b[39m(Distribution, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mValueError\u001b[0m: Expected parameter probs (Tensor of shape (200, 1, 500)) of distribution Bernoulli(probs: torch.Size([200, 1, 500])) to satisfy the constraint Interval(lower_bound=0.0, upper_bound=1.0), but found invalid values:\ntensor([[[nan, nan, nan,  ..., nan, nan, nan]],\n\n        [[nan, nan, nan,  ..., nan, nan, nan]],\n\n        [[nan, nan, nan,  ..., nan, nan, nan]],\n\n        ...,\n\n        [[nan, nan, nan,  ..., nan, nan, nan]],\n\n        [[nan, nan, nan,  ..., nan, nan, nan]],\n\n        [[nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<SigmoidBackward0>)"
     ]
    }
   ],
   "source": [
    "# Run experiments\n",
    "\n",
    "for config in configs:\n",
    "\n",
    "    # Make sure that these are \"reinitialised\"\n",
    "    p_m, p_n, criterion = None, None, None\n",
    "\n",
    "    p_m = Rbm(weights=weights.clone(), vis_bias=vis_bias.clone(), hidden_bias=hidden_bias.clone())\n",
    "    \n",
    "    p_n = RbmNoiseDistr(rbm=p_m)\n",
    "   \n",
    "    if config[\"mcmc_steps\"] is not None:\n",
    "        criterion = config[\"criterion\"](p_m, p_n, num_neg_samples, config[\"mcmc_steps\"])\n",
    "    else:\n",
    "        criterion = config[\"criterion\"](p_m, p_n, num_neg_samples)\n",
    "\n",
    "    save_dir = None\n",
    "    _ = train_model(criterion, placeholder_metric, train_loader, save_dir, num_epochs=num_epochs,\n",
    "                    decaying_lr=True, weight_decay=1e-3, stopping_condition=no_stopping)\n",
    "    \n",
    "    # Check test accuracy of model\n",
    "    acc = rbm_acc(p_m, test_loader)\n",
    "    print(\"Model accuracy: {}\".format(acc))\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(p_m.state_dict(), \"res/params_\" + config[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b6037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "\n",
    "num_samples = 8\n",
    "\n",
    "p_m = Rbm(weights=weights.clone(), vis_bias=vis_bias.clone(), hidden_bias=hidden_bias.clone())\n",
    "for config in configs:\n",
    "    p_m.load_state_dict(torch.load(\"res/params_\" + config[\"label\"]))\n",
    "    y_pred = p_m.sample(training_data.y[:num_samples, :], k=100) # Eller hur fungerar detta? torch.randn((num_samples, num_dims))?\n",
    "    \n",
    "    plt.imshow(np.transpose(torchvision.utils.make_grid(y_pred.reshape(-1, 1, 28, 28), nrow=4).numpy(), (1, 2, 0)))\n",
    "    plt.title(config[\"label\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793f45e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
