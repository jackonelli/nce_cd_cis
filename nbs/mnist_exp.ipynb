{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21d34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.nce.cd_cnce import CdCnceCrit\n",
    "from src.nce.cd_mh import CdMHCrit\n",
    "from src.nce.per_cnce import PersistentCondNceCrit\n",
    "from src.cd.cd_gibbs import CdGibbsCrit\n",
    "from src.cd.pers_gibbs import PersistentCdGibbsCrit\n",
    "\n",
    "from src.noise_distr.rbm_noise_distr import RbmNoiseDistr\n",
    "\n",
    "from src.models.rbm.rbm import Rbm\n",
    "from src.data.mnist import MnistDataset\n",
    "\n",
    "from src.training.model_training import train_model\n",
    "from src.training.training_utils import no_stopping\n",
    "\n",
    "from src.experiments.mnist_exp_utils import initialise_params\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4307bfe",
   "metadata": {},
   "source": [
    "## EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4eb4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data specs\n",
    "num_dims = 28**2\n",
    "\n",
    "# Training specs\n",
    "num_neg_samples = 2\n",
    "lr = 0.01\n",
    "batch_size = 64\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40698ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy of model\n",
    "def rbm_acc(rbm, data_loader, k=100):\n",
    "    acc = 0\n",
    "    for i, (y, idx) in enumerate(data_loader, 0):\n",
    "        y_pred = rbm.sample(y, k=k)\n",
    "        acc += (y_pred == y).type(torch.float).mean(dim=-1).sum()\n",
    "        \n",
    "    return acc / len(data_loader.dataset)\n",
    "\n",
    "def placeholder_metric(model):\n",
    "    return model.weights.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations to consider in experiments \n",
    "\n",
    "config_conditional_multi = {\n",
    "    \"criterion\": CdCnceCrit,\n",
    "    \"label\": \"cd_cnce\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": 1,\n",
    "}\n",
    "\n",
    "config_per_cnce = {\n",
    "    \"criterion\": PersistentCondNceCrit,\n",
    "    \"label\": \"per_cnce\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": None,\n",
    "}\n",
    "\n",
    "config_cd_mh = {\n",
    "    \"criterion\": CdMHCrit,\n",
    "    \"label\": \"cd_mh\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": 1,\n",
    "}\n",
    "\n",
    "\n",
    "config_cd_gibbs = {\n",
    "    \"criterion\": CdGibbsCrit,\n",
    "    \"label\": \"cd_gibbs\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": 1,\n",
    "}\n",
    "\n",
    "config_pers_gibbs = {\n",
    "    \"criterion\": PersistentCdGibbsCrit,\n",
    "    \"label\": \"pers_gibbs\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": None,\n",
    "}\n",
    "\n",
    "\n",
    "configs = [config_per_cnce]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c8c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data \n",
    "training_data = MnistDataset(train=True, root_dir=\"../src/data/datasets/\")\n",
    "training_data.y = training_data.y[:20000, :]\n",
    "training_data.num_samples = 20000\n",
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "                             \n",
    "test_data = MnistDataset(train=False, root_dir=\"../src/data/datasets/\")\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090b9998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise model       \n",
    "weights, vis_bias, hidden_bias = initialise_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a08bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiments\n",
    "\n",
    "for config in configs:\n",
    "\n",
    "    # Make sure that these are \"reinitialised\"\n",
    "    p_m, p_n, criterion = None, None, None\n",
    "\n",
    "    p_m = Rbm(weights=weights.clone(), vis_bias=vis_bias.clone(), hidden_bias=hidden_bias.clone())\n",
    "    \n",
    "    if config[\"conditional_noise_distr\"]:\n",
    "        p_n = RbmNoiseDistr(p_m)\n",
    "    else:\n",
    "        p_n = None\n",
    "   \n",
    "    if config[\"mcmc_steps\"] is not None:\n",
    "        criterion = config[\"criterion\"](p_m, p_n, num_neg_samples, config[\"mcmc_steps\"])\n",
    "    else:\n",
    "        criterion = config[\"criterion\"](p_m, p_n, num_neg_samples)\n",
    "\n",
    "    save_dir = None\n",
    "    _ = train_model(criterion, placeholder_metric, train_loader, save_dir, num_epochs=num_epochs,\n",
    "                    decaying_lr=True, weight_decay=1e-3, stopping_condition=no_stopping)\n",
    "    \n",
    "    # Check test accuracy of model\n",
    "    acc = rbm_acc(p_m, test_loader)\n",
    "    print(\"Model accuracy: {}\".format(acc))\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(p_m.state_dict(), \"res/params_\" + config[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b6037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "\n",
    "num_samples = 8\n",
    "fig, ax = plt.subplots(len(configs), 2)\n",
    "\n",
    "\n",
    "if ax.ndim == 1:\n",
    "    ax = ax.reshape(1, -1)\n",
    "\n",
    "p_m = Rbm(weights=weights.clone(), vis_bias=vis_bias.clone(), hidden_bias=hidden_bias.clone())\n",
    "for i, config in enumerate(configs):\n",
    "    p_m.load_state_dict(torch.load(\"res/params_\" + config[\"label\"]))\n",
    "    y_true = training_data.y[:num_samples, :] # torch.randn((num_samples, num_dims))?\n",
    "    y_pred = p_m.sample(y_true, k=10) \n",
    "    \n",
    "    ax[i, 0].imshow(np.transpose(torchvision.utils.make_grid(y_true.reshape(-1, 1, 28, 28), nrow=4).numpy(), (1, 2, 0)))\n",
    "    ax[i, 0].set_title(config[\"label\"] + \" real\")\n",
    "    \n",
    "    ax[i, 1].imshow(np.transpose(torchvision.utils.make_grid(y_pred.reshape(-1, 1, 28, 28), nrow=4).numpy(), (1, 2, 0)))\n",
    "    ax[i, 1].set_title(config[\"label\"] + \" generated\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e0a893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
