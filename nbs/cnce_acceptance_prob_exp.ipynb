{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21d34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tikzplotlib\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.nce.cd_cnce import CdCnceCrit\n",
    "from src.nce.cd_mh import CdMHCrit\n",
    "\n",
    "from src.noise_distr.conditional_normal import ConditionalMultivariateNormal\n",
    "\n",
    "from src.models.ring_model.ring_model import RingModel, RingModelNCE, unnorm_ring_model_log_pdf\n",
    "from src.data.ring_model_dataset import RingModelDataset\n",
    "\n",
    "from src.training.model_training import train_model\n",
    "from src.training.training_utils import PrecisionErrorMetric, no_stopping, remove_file\n",
    "\n",
    "from src.experiments.ring_model_exp_utils import generate_true_params, initialise_params\n",
    "from src.experiments.noise_distr_utils import get_nce_noise_distr_par, get_cnce_noise_distr_par\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4307bfe",
   "metadata": {},
   "source": [
    "## EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4eb4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data specs\n",
    "num_dims = 5\n",
    "\n",
    "# TODO: fler samples högre dim??\n",
    "# TODO: göra enklare skattning av eps (typ std från data)?\n",
    "\n",
    "# Experiments specs\n",
    "num_samples = 200\n",
    "num_neg_samples = [2, 5]\n",
    "reps = 100\n",
    "\n",
    "# Training specs\n",
    "batch_size = 20\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations to consider in experiments \n",
    "\n",
    "config_conditional_multi = {\n",
    "    \"criterion\": CdCnceCrit,\n",
    "    \"label\": \"cd_cnce\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": 1,\n",
    "}\n",
    "\n",
    "config_cd_mh = {\n",
    "    \"criterion\": CdMHCrit,\n",
    "    \"label\": \"cd_mh\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": 1,\n",
    "}\n",
    "\n",
    "configs = [config_conditional_multi, config_cd_mh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c814b4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_cnce_noise_distr_par(y):\n",
    "    epsilon = torch.std(y, dim=-1).mean()\n",
    "\n",
    "    return torch.eye(y.shape[-1]) * epsilon ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a08bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiments\n",
    "\n",
    "# Data saved over reps\n",
    "error_res = np.zeros((len(num_neg_samples), len(configs), int(np.ceil(num_samples / batch_size) * num_epochs), reps))\n",
    "acc_prob_res = np.zeros((len(num_neg_samples), len(configs), len(configs), int(np.ceil(num_samples / batch_size) * num_epochs), reps))\n",
    "\n",
    "\n",
    "for i, J in enumerate(num_neg_samples):\n",
    "    for rep in range(reps):\n",
    "\n",
    "        # Get data \n",
    "        mu, precision, _ = generate_true_params()\n",
    "        error_metric = PrecisionErrorMetric(true_precision=precision).metric            \n",
    "\n",
    "        training_data = RingModelDataset(sample_size=num_samples, num_dims=num_dims, mu=mu, precision=precision, \n",
    "                                         root_dir=\"res/datasets/ring_data_size_\" + str(num_samples) + \"_nn_\" + str(J) + \"_rep_\" + str(rep))\n",
    "        train_loader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # Initialise           \n",
    "        _, log_precision_init, log_z_init = initialise_params()\n",
    "\n",
    "        # Get noise distr. params\n",
    "        p_m = RingModel(mu=mu, log_precision=log_precision_init.clone())\n",
    "        cov_noise_cnce = get_simple_cnce_noise_distr_par(training_data.get_full_data()) #get_cnce_noise_distr_par(training_data.get_full_data(), J, p_m)\n",
    "\n",
    "        for j, config in enumerate(configs):\n",
    "\n",
    "            # Remove old acc. prob.\n",
    "            remove_file(\"res/\" + config[\"label\"] + \"_num_neg_\" + str(J) + \"_cd_cnce_acc_prob.npy\")\n",
    "            remove_file(\"res/\" + config[\"label\"] + \"_num_neg_\" + str(J) + \"_cd_mh_acc_prob.npy\")\n",
    "\n",
    "            # Make sure that these are \"reinitialised\"\n",
    "            p_m, p_n, criterion = None, None, None\n",
    "\n",
    "            if config[\"estimate_part_fn\"]:\n",
    "                p_m = RingModelNCE(mu=mu, log_precision=log_precision_init.clone(), log_part_fn=log_z_init.clone())\n",
    "            else:\n",
    "                p_m = RingModel(mu=mu, log_precision=log_precision_init.clone())\n",
    "\n",
    "            p_n = ConditionalMultivariateNormal(cov=cov_noise_cnce)\n",
    "\n",
    "            criterion = config[\"criterion\"](p_m, p_n, J, config[\"mcmc_steps\"], save_acc_prob=True)\n",
    "\n",
    "            save_dir_pre = \"res/\" + config[\"label\"] + \"_num_neg_\" + str(num_neg_samples[i])\n",
    "            _ = train_model(criterion, error_metric, train_loader, save_dir_pre + \"_error\", num_epochs=num_epochs,\n",
    "                            stopping_condition=no_stopping)\n",
    "\n",
    "            # Fetch data that has been saved\n",
    "            error_res[i, j, :, rep] = np.load(save_dir_pre + \"_error.npy\")\n",
    "            acc_prob_res[i, j, 0, :, rep] = np.load(save_dir_pre + \"_\" + configs[0][\"label\"] + \"_acc_prob.npy\").mean(axis=0)\n",
    "            acc_prob_res[i, j, 1, :, rep] = np.load(save_dir_pre + \"_\" + configs[1][\"label\"] + \"_acc_prob.npy\").mean(axis=0)\n",
    "\n",
    "# Save res\n",
    "np.save(\"res/final_param_error_cnce_acceptance_prob_exp_num_samples_\" + str(num_samples), error_res)\n",
    "np.save(\"res/final_acc_prob_cnce_acceptance_prob_exp_num_samples_\" + str(num_samples), acc_prob_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c560bfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "error_res = np.load(\"res/final_param_error_cnce_acceptance_prob_exp_num_samples_\" + str(num_samples) + \".npy\")\n",
    "acc_prob_res = np.load(\"res/final_acc_prob_cnce_acceptance_prob_exp_num_samples_\" + str(num_samples) + \".npy\")\n",
    "\n",
    "\n",
    "colors = ['C0', 'C1']\n",
    "assert len(colors) >= len(configs), \"Need one colour for each method\"\n",
    "\n",
    "for i, J in enumerate(num_neg_samples):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    for j, config in enumerate(configs):\n",
    "        ax[0].plot(np.log(error_res[i, j, :, :]).mean(axis=-1), color=colors[j], label=config[\"label\"])\n",
    "        #ax[0].errorbar(np.arange(error_res.shape[-2]) + 1, np.log(error_res[i, j, :, :]).mean(axis=-1), yerr=np.log(error_res[i, j, :, :]).std(axis=-1), color=colors[j], label=config[\"label\"], errorevery=10)\n",
    "\n",
    "        for k, config_2 in enumerate(configs):\n",
    "            ax[j + 1].plot(acc_prob_res[i, j, k, :, :].mean(axis=-1), color=colors[k], label=config_2[\"label\"])\n",
    "            #ax[k+1].errorbar(np.arange(acc_prob_res.shape[-2]) + 1, np.log(acc_prob_res[i, j, k, :, :]).mean(axis=-1), yerr=np.log(acc_prob_res[i, j, k, :, :]).std(axis=-1),\n",
    "            #              color=colors[k], label=config_2[\"label\"], errorevery=10)\n",
    "\n",
    "            ax[j + 1].set_xlabel(\"Iter.\")\n",
    "            ax[j + 1].set_ylabel(\"Acc. prob., \" + config[\"label\"])\n",
    "\n",
    "    ax[0].set_xlabel(\"Iter.\")\n",
    "    ax[0].set_ylabel(\"Log(SE)\")\n",
    "    ax[0].legend()            \n",
    "    ax[1].set_title(\"Num samples: {}, Num neg. samples: {}\".format(num_samples, num_neg_samples[i]))    \n",
    "\n",
    "    tikzplotlib.save(\"res/cnce_acc_prob_res_num_samples_\" + str(N) + \"_num_neg_samples_\" + str(J) + \".tex\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e1da76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
