{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tikzplotlib\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.nce.cd_cnce import CdCnceCrit\n",
    "from src.nce.cd_mh_cnce import CdMHCnceCrit\n",
    "from src.nce.per_cnce import PersistentCondNceCrit\n",
    "from src.nce.per_cnce_batch import PersistentCondNceCritBatch\n",
    "from src.nce.per_cnce_batch import PersistentCondNceCritBatch\n",
    "from src.nce.per_mh_cnce_batch import PersistentMHCnceCritBatch\n",
    "\n",
    "from src.noise_distr.conditional_normal import ConditionalMultivariateNormal\n",
    "\n",
    "from src.models.ring_model.ring_model import RingModel, RingModelNCE, unnorm_ring_model_log_pdf\n",
    "from src.data.ring_model_dataset import RingModelDataset\n",
    "\n",
    "from src.training.model_training import train_model\n",
    "from src.training.training_utils import PrecisionErrorMetric, no_stopping, remove_file\n",
    "\n",
    "from src.experiments.ring_model_exp_utils import generate_true_params, initialise_params\n",
    "from src.experiments.noise_distr_utils import get_nce_noise_distr_par, get_cnce_noise_distr_par\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data specs\n",
    "num_dims = 5\n",
    "\n",
    "# Experiments specs\n",
    "num_samples = 1000\n",
    "num_neg_samples = [5, 10]\n",
    "reps = 100\n",
    "\n",
    "# Training specs\n",
    "batch_size = 20\n",
    "num_epochs = 50\n",
    "base_lr = 0.01\n",
    "lr = base_lr * batch_size ** 0.5\n",
    "lr_factor = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations to consider in experiments \n",
    "\n",
    "config_cnce = {\n",
    "    \"criterion\": CdCnceCrit,\n",
    "    \"label\": \"cd_cnce\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": 1,\n",
    "    \"calc_acc_prob\": True\n",
    "}\n",
    "\n",
    "config_cd_mh = {\n",
    "    \"criterion\": CdMHCnceCrit,\n",
    "    \"label\": \"cd_mh\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": 1,\n",
    "    \"calc_acc_prob\": True\n",
    "}\n",
    "\n",
    "config_pers_cnce = {\n",
    "    \"criterion\": PersistentCondNceCrit,\n",
    "    \"label\": \"pers_cnce\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": None,\n",
    "}\n",
    "\n",
    "config_pers_cnce_batch = {\n",
    "    \"criterion\": PersistentCondNceCritBatch,\n",
    "    \"label\": \"pers_cnce\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": None,\n",
    "    \"calc_acc_prob\": True\n",
    "}\n",
    "\n",
    "config_pers_mh_cnce_batch = {\n",
    "    \"criterion\": PersistentMHCnceCritBatch,\n",
    "    \"label\": \"pers_mh_cnce\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": None,\n",
    "    \"calc_acc_prob\": True\n",
    "}\n",
    "\n",
    "configs = [config_cnce, config_pers_cnce_batch, config_cd_mh, config_pers_mh_cnce_batch]\n",
    "labels = ['CNCE', 'P-CNCE', 'MH-CNCE', 'P-MH-CNCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_cnce_noise_distr_par(y):\n",
    "    epsilon = torch.std(y, dim=-1).mean()\n",
    "\n",
    "    return torch.eye(y.shape[-1]) * epsilon ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiments\n",
    "\n",
    "# Data saved over reps\n",
    "error_res = np.zeros((len(num_neg_samples), len(configs), int(np.ceil(num_samples / batch_size) * num_epochs), reps))\n",
    "acc_prob_res = np.zeros((len(num_neg_samples), len(configs), 2, int(np.ceil(num_samples / batch_size) * num_epochs), reps))\n",
    "\n",
    "for i, J in enumerate(num_neg_samples):\n",
    "    for rep in range(reps):\n",
    "\n",
    "        # Get data \n",
    "        mu, precision, _ = generate_true_params()\n",
    "        error_metric = PrecisionErrorMetric(true_precision=precision).metric            \n",
    "\n",
    "        training_data = RingModelDataset(sample_size=num_samples, num_dims=num_dims, mu=mu, precision=precision, \n",
    "                                         root_dir=\"res/datasets/ring_data_size_\" + str(num_samples) + \"_nn_\" + str(J) + \"_rep_\" + str(rep))\n",
    "        train_loader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # Initialise           \n",
    "        _, log_precision_init, log_z_init = initialise_params()\n",
    "\n",
    "        # Get noise distr. params\n",
    "        p_m = RingModel(mu=mu, log_precision=log_precision_init.clone())\n",
    "        cov_noise_cnce = get_simple_cnce_noise_distr_par(training_data.get_full_data()) #get_cnce_noise_distr_par(training_data.get_full_data(), J, p_m)\n",
    "\n",
    "        for j, config in enumerate(configs):\n",
    "\n",
    "            # Remove old acc. prob.\n",
    "            remove_file(\"res/\" + config[\"label\"] + \"_num_neg_\" + str(J) + \"_cd_cnce_acc_prob.npy\")\n",
    "            remove_file(\"res/\" + config[\"label\"] + \"_num_neg_\" + str(J) + \"_cd_mh_acc_prob.npy\")\n",
    "\n",
    "            # Make sure that these are \"reinitialised\"\n",
    "            p_m, p_n, criterion = None, None, None\n",
    "\n",
    "            if config[\"estimate_part_fn\"]:\n",
    "                p_m = RingModelNCE(mu=mu, log_precision=log_precision_init.clone(), log_part_fn=log_z_init.clone())\n",
    "            else:\n",
    "                p_m = RingModel(mu=mu, log_precision=log_precision_init.clone())\n",
    "\n",
    "            p_n = ConditionalMultivariateNormal(cov=cov_noise_cnce)\n",
    "            \n",
    "            if config[\"mcmc_steps\"] is not None: \n",
    "                criterion = config[\"criterion\"](p_m, p_n, J, config[\"mcmc_steps\"], save_acc_prob=config[\"calc_acc_prob\"])\n",
    "            else:\n",
    "                criterion = config[\"criterion\"](p_m, p_n, J, save_acc_prob=config[\"calc_acc_prob\"])\n",
    "\n",
    "            save_dir_pre = \"res/\" + config[\"label\"] + \"_num_neg_\" + str(num_neg_samples[i])\n",
    "            _ = train_model(criterion, error_metric, train_loader, save_dir_pre + \"_error\", num_epochs=num_epochs,\n",
    "                            stopping_condition=no_stopping, lr=lr, decaying_lr=True, lr_factor=lr_factor)\n",
    "\n",
    "            # Fetch data that has been saved\n",
    "            error_res[i, j, :, rep] = np.load(save_dir_pre + \"_error.npy\")\n",
    "            if config[\"calc_acc_prob\"]:\n",
    "                acc_prob_res[i, j, 0, :, rep] = np.load(save_dir_pre + \"_\" + \"cd_cnce\" + \"_acc_prob.npy\").mean(axis=0)\n",
    "                acc_prob_res[i, j, 1, :, rep] = np.load(save_dir_pre + \"_\" + \"cd_mh\" + \"_acc_prob.npy\").mean(axis=0)\n",
    "\n",
    "# Save res\n",
    "np.save(\"res/final_param_error_cnce_exp_w_pers_mh_num_samples_\" + str(num_samples), error_res)\n",
    "np.save(\"res/final_acc_prob_cnce_exp_w_pers_mh_num_samples_\" + str(num_samples), acc_prob_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "\n",
    "#error_res = np.load(\"res/final_param_error_cnce_exp_w_pers_mh_num_samples_\" + str(num_samples) + \".npy\")\n",
    "#acc_prob_res = np.load(\"res/final_acc_prob_cnce_exp_w_pers_mh_num_samples_\" + str(num_samples) + \".npy\")\n",
    "\n",
    "error_res = np.load(\"res/final_param_error_cnce_exp_w_pers_mh_num_samples_\" + str(num_samples) + \"bs_20.npy\")\n",
    "acc_prob_res = np.load(\"res/final_acc_prob_cnce_exp_w_pers_mh_num_samples_\" + str(num_samples) + \"bs_20.npy\")\n",
    "\n",
    "colors = [[31/255,68/255,156/255], [240/255,80/255,57/255], [124/255,161/255,204/255], [238/255,186/255,180/255]]\n",
    "assert len(colors) >= len(configs), \"Need one colour for each method\"\n",
    "\n",
    "def get_statistics(data):\n",
    "    median = np.median(data, axis=-1)\n",
    "    upper_quartile = np.max(data, axis=-1)\n",
    "    lower_quartile = np.min(data, axis=-1)\n",
    "    \n",
    "    return median, upper_quartile, lower_quartile\n",
    "        \n",
    "def skip_list_item(lst: list, nth: int):\n",
    "    \"\"\"Skip every nth element in list\"\"\"\n",
    "    return list(\n",
    "        map(\n",
    "            lambda val: val[1],\n",
    "            filter(lambda idx_row: (idx_row[0] % nth == 0), enumerate(lst)),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "plot_all = False\n",
    "num_its = error_res.shape[-2]\n",
    "x = np.arange(num_its) + 1\n",
    "\n",
    "\n",
    "if num_samples == 1000:\n",
    "    x = skip_list_item(x, 5)\n",
    "    \n",
    "\n",
    "for i, J in enumerate(num_neg_samples):\n",
    "    \n",
    "    if plot_all:\n",
    "        fig, ax = plt.subplots(1, 4, figsize=(16, 5))\n",
    "    else:\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(16, 5))\n",
    "        \n",
    "    for j, config in enumerate(configs):\n",
    "        \n",
    "        if plot_all:\n",
    "            for k in range(reps):\n",
    "                if num_samples == 1000:\n",
    "                    data = skip_list_item(error_res[i, j, :, k], 5)\n",
    "                else:\n",
    "                    data = error_res[i, j, :, k]\n",
    "                    \n",
    "                if k == 0:\n",
    "                    ax[j].plot(x, data, color=colors[j], label=labels[j])\n",
    "                else:\n",
    "                    ax[j].plot(x, data, color=colors[j])\n",
    "                    \n",
    "            ax[j].legend()\n",
    "            ax[j].set_ylim([-1, 100])        \n",
    "            ax[j].set_xlabel(\"Iter.\")\n",
    "            ax[j].set_ylabel(\"Avg. Sq. Error\")\n",
    "            \n",
    "\n",
    "        else:\n",
    "            ax[0].set_yscale('log')\n",
    "            \n",
    "            if num_samples == 1000:\n",
    "                err_data = skip_list_item(error_res[i, j, :, :], 5)\n",
    "                cnce_data = skip_list_item(acc_prob_res[i, j, 0, :, :], 5)\n",
    "                mh_cnce_data = skip_list_item(acc_prob_res[i, j, 1, :, :], 5)\n",
    "\n",
    "            else:\n",
    "                err_data = error_res[i, j, :, :]\n",
    "                cnce_data = acc_prob_res[i, j, 0, :, :]\n",
    "                mh_cnce_data = acc_prob_res[i, j, 1, :, :]\n",
    "\n",
    "                \n",
    "            err_median, err_upper_quartile, err_lower_quartile = get_statistics(err_data)\n",
    "\n",
    "            ax[0].plot(x, err_median, color=colors[j], label=labels[j])\n",
    "            ax[0].plot(x, err_upper_quartile, '--', color=colors[j])\n",
    "\n",
    "            cnce_median, cnce_upper_quartile, cnce_lower_quartile = get_statistics(cnce_data)\n",
    "            mh_cnce_median, mh_cnce_upper_quartile, mh_cnce_lower_quartile = get_statistics(mh_cnce_data)\n",
    "        \n",
    "            if j == 0 or j == 1:\n",
    "                ax[1].plot(x, cnce_median, color=colors[j], label=labels[j])\n",
    "                ax[1].plot(x, mh_cnce_median, color=colors[j+2], label=labels[j+2])\n",
    "            else:\n",
    "                ax[2].plot(x, cnce_median, color=colors[j-2], label=labels[j-2])\n",
    "                ax[2].plot(x, mh_cnce_median, color=colors[j], label=colors[j-2])\n",
    "                \n",
    "\n",
    "    if plot_all:\n",
    "         tikzplotlib.save(\"res/cnce_acc_prob_res_num_samples_\" + str(num_samples) + \"_num_neg_samples_\" + str(J) + \"_all.tex\")\n",
    "    else:\n",
    "        ax[0].set_xlabel(\"Iter.\")\n",
    "        ax[0].set_ylabel(\"Sq. Error\")\n",
    "        \n",
    "        ax[1].set_xlabel(\"Iter.\")\n",
    "        ax[1].set_ylabel(\"Acc. Prob., (P-)CNCE\")\n",
    "        ax[1].legend(loc='upper center', bbox_to_anchor=(0.5, 1.12), ncol=4, fancybox=True, shadow=True)\n",
    "\n",
    "        ax[2].set_xlabel(\"Iter.\")\n",
    "        ax[2].set_ylabel(\"Acc. Prob., (P-)MH-CNCE\")\n",
    "        \n",
    "        tikzplotlib.save(\"res/cnce_acc_prob_res_num_samples_\" + str(num_samples) + \"_num_neg_samples_\" + str(J) + \".tex\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
