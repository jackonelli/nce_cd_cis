{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b21d34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.nce.cond_cd_cnce import CondCdCnceCrit\n",
    "from src.nce.cond_per_cnce import CondPersistentCnceCrit\n",
    "\n",
    "\n",
    "from src.noise_distr.conditional_bernoulli import ConditionalMultivariateBernoulli\n",
    "from src.noise_distr.conditional_bernoulli import SpatialConditionalMultivariateBernoulli\n",
    "\n",
    "from src.models.rbm.conditional_rbm import CondRbm\n",
    "from src.data.mnist_w_labels import MnistDatasetWLabs\n",
    "\n",
    "from src.training.model_training import train_model\n",
    "from src.training.training_utils import no_stopping\n",
    "\n",
    "from src.experiments.mnist_exp_utils import initialise_cond_rbm_params\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4307bfe",
   "metadata": {},
   "source": [
    "## EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa4eb4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data specs\n",
    "img_dim = 28\n",
    "num_dims = img_dim**2\n",
    "num_classes = 10\n",
    "\n",
    "# Model specs\n",
    "num_hidden = 200\n",
    "\n",
    "# Training specs\n",
    "num_neg_samples = 5\n",
    "lr = 0.1\n",
    "batch_size = 64\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40698ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy of model\n",
    "def rbm_acc(rbm, data_loader, k=100):\n",
    "    acc = 0\n",
    "    for i, (y, idx) in enumerate(data_loader, 0):\n",
    "        _, y_pred = rbm.sample(y, k=k)\n",
    "        acc += (y_pred == y).type(torch.float).mean(dim=-1).sum()\n",
    "        \n",
    "    return acc / len(data_loader.dataset)\n",
    "\n",
    "def placeholder_metric(model):\n",
    "    return model.weights.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations to consider in experiments \n",
    "\n",
    "config_cnce = {\n",
    "    \"criterion\": CondCdCnceCrit,\n",
    "    \"label\": \"cd_cnce\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": 1,\n",
    "}\n",
    "\n",
    "config_per_cnce = {\n",
    "    \"criterion\": CondPersistentCnceCrit,\n",
    "    \"label\": \"pers_cd_cnce\",\n",
    "    \"estimate_part_fn\": False,\n",
    "    \"conditional_noise_distr\": True,\n",
    "    \"mcmc_steps\": None,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "configs = [config_cnce]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c8c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data \n",
    "num_classes = 5\n",
    "training_data = MnistDatasetWLabs(train=True, root_dir=\"../src/data/datasets/\", num_classes=num_classes)\n",
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "                             \n",
    "test_data = MnistDatasetWLabs(train=False, root_dir=\"../src/data/datasets/\", num_classes=num_classes)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090b9998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise model       \n",
    "weights, vis_bias, hidden_bias, class_weights = initialise_cond_rbm_params(num_visible=num_dims, num_hidden=num_hidden, num_conditional=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935b71c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cond_bern_params(y, eps=1e-1):\n",
    "    num_dims = y.shape[-1]\n",
    "    p_0, p_1 = torch.zeros((num_dims,)), torch.zeros((num_dims,))\n",
    "    for i in range(num_dims):\n",
    "                \n",
    "        if y[y[:, i] < 0.5, i].size()[0] == 0:\n",
    "            p_0[i] = 0.5\n",
    "        else:\n",
    "            p_0[i] = y[y[:, i] < 0.5, i].mean()\n",
    "        \n",
    "        if y[y[:, i] >= 0.5, i].size()[0] == 0:\n",
    "            p_1[i] = 0.5\n",
    "        else:\n",
    "            p_1[i] = y[y[:, i] >= 0.5, i].mean()\n",
    "\n",
    "    p_0[p_0 < eps] = eps\n",
    "    p_1[p_1 > 1 - eps] = 1 - eps\n",
    "    return p_0, p_1\n",
    "        \n",
    "p_0, p_1 = get_cond_bern_params(training_data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c568dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test noise distr. params\n",
    "\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "\n",
    "num_samples = 16\n",
    "y_true = training_data.y[:num_samples, :].clone()\n",
    "y_true[y_true >= 0.5] = 1.0\n",
    "y_true[y_true < 0.5] = 0.0\n",
    "y_sample = (1 - y_true) * torch.distributions.Bernoulli(p_0).sample((1,)) + y_true * torch.distributions.Bernoulli(p_1).sample((1,))\n",
    "\n",
    "\n",
    "ax[0].imshow(np.transpose(torchvision.utils.make_grid(y_true.reshape(-1, 1, 28, 28), nrow=4).numpy(), (1, 2, 0)))\n",
    "ax[1].imshow(np.transpose(torchvision.utils.make_grid(y_sample.reshape(-1, 1, 28, 28), nrow=4).numpy(), (1, 2, 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a08bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiments\n",
    "\n",
    "for config in configs:\n",
    "    \n",
    "    # Make sure that these are \"reinitialised\"\n",
    "    p_m, p_n, criterion = None, None, None\n",
    "\n",
    "    p_m = CondRbm(weights=weights.clone(), vis_bias=vis_bias.clone(), hidden_bias=hidden_bias.clone(), class_weights=class_weights.clone())\n",
    "\n",
    "    \n",
    "    if config[\"conditional_noise_distr\"]:\n",
    "        p_n = ConditionalMultivariateBernoulli(p_0, p_1) # SpatialConditionalMultivariateBernoulli(p_0, p_1)\n",
    "    else:\n",
    "        p_n = None\n",
    "   \n",
    "    if config[\"mcmc_steps\"] is not None:\n",
    "        criterion = config[\"criterion\"](p_m, p_n, num_neg_samples, config[\"mcmc_steps\"])\n",
    "    else:\n",
    "        criterion = config[\"criterion\"](p_m, p_n, num_neg_samples)\n",
    "\n",
    "    save_dir = None\n",
    "    _ = train_model(criterion, placeholder_metric, train_loader, save_dir, num_epochs=num_epochs,\n",
    "                    decaying_lr=True, weight_decay=1e-3, stopping_condition=no_stopping, Adam=False)\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(p_m.state_dict(), \"res/params_rbm_\" + config[\"label\"])\n",
    "    \n",
    "    # Check test accuracy of model\n",
    "    #acc = rbm_acc(p_m, test_loader)\n",
    "    #print(\"Model accuracy: {}\".format(acc))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b6037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "configs = [config_cnce, config_per_cnce]\n",
    "\n",
    "num_samples = 8\n",
    "fig, ax = plt.subplots(len(configs), 2)\n",
    "\n",
    "if ax.ndim == 1:\n",
    "    ax = ax.reshape(1, -1)\n",
    "\n",
    "p_m = CondRbm(weights=weights.clone(), vis_bias=vis_bias.clone(), hidden_bias=hidden_bias.clone(), class_weights=class_weights.clone()\n",
    ")\n",
    "\n",
    "for i, config in enumerate(configs):\n",
    "    p_m.load_state_dict(torch.load(\"res/params_rbm_\" + config[\"label\"]))\n",
    "    \n",
    "    #y_true = training_data.y[:num_samples, :] #  torch.distributions.Bernoulli(0.5).sample((num_samples, num_dims)) #\n",
    "    #y_true_pred_prob, y_true_pred = p_m.sample(y_true.clone(), k=10000)\n",
    "    \n",
    "    y_noise = torch.distributions.Bernoulli(0.5).sample((num_samples, num_hidden)) \n",
    "    x = torch.distributions.OneHotCategorical(torch.tensor([1 / num_classes] * num_classes)).sample((num_samples,))\n",
    "    print(\"Sampled classes: {}\".format(x.argmax(dim=-1).tolist()))\n",
    "    y_pred_prob, y_pred = p_m.sample_from_hidden(y_noise, x, k=100) \n",
    "    \n",
    "    ax[i, 0].imshow(np.transpose(torchvision.utils.make_grid(y_pred_prob.reshape(-1, 1, 28, 28), nrow=4).numpy(), (1, 2, 0)))\n",
    "    ax[i, 0].set_title(config[\"label\"] + \" predicted probabilities\")\n",
    "    \n",
    "    ax[i, 1].imshow(np.transpose(torchvision.utils.make_grid(y_pred.reshape(-1, 1, 28, 28), nrow=4).numpy(), (1, 2, 0)))\n",
    "    ax[i, 1].set_title(config[\"label\"] + \" samples\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12381aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: SGD verkar fungera bättre för CNCE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
